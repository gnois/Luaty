var ffi = require("ffi")
var stack = require("lt.stack")
var Keyword = require("lt.reserved")
Keyword.var = true

var int64 = ffi.typeof('int64_t')
var uint64 = ffi.typeof('uint64_t')
var complex = ffi.typeof('complex')

var ASCII_0, ASCII_9 = 48, 57
var ASCII_a, ASCII_f, ASCII_z = 97, 102, 122
var ASCII_A, ASCII_Z = 65, 90
var END_OF_STREAM = -1


var TokenSymbol = { TK_lambda = '->', TK_curry = '~>', TK_ge = '>=', TK_le = '<=' , TK_concat = '..', TK_eq = '==', TK_ne = '~=', TK_indent = '<indent>', TK_dedent = '<dedent>', TK_newline = '<newline>', TK_eof = '<eof>' }

var IsNewLine = { ['\n'] = true, ['\r'] = true }

var IsEscape = { a = true, b = true, f = true, n = true, r = true, t = true, v = true }
 
var token2str = \tok ->
	if string.match(tok, "^TK_")
		return TokenSymbol[tok] or string.sub(tok, 4)
	else
		return tok


var throw = \chunkname, line, em, ... ->
	var emfmt = string.format(em, ...)
	var msg = string.format("%s:%d   %s", chunkname, line, emfmt)
	error("LT-ERROR" .. msg, 0)


var fmt_token = \token ->
	if token
		var tok
		if token == 'TK_name' or token == 'TK_string' or token == 'TK_number'
			tok = buff
		else
			tok = string.format("'%s'", token2str(token))
		-- replace % with %%, so as not to confuse string.format() later
		return (string.gsub(tok, "%%.", \p -> return '%' .. p ))


var fmt_error = \token, em, template ->
	var tok = fmt_token(token)
	if tok
		em = string.format(template, em, tok)
	return em

var char_isalnum = \c ->
	if type(c) == 'string'
		var b = string.byte(c)
		if b >= ASCII_0 and b <= ASCII_9
			return true
		else if b >= ASCII_a and b <= ASCII_z
			return true
		else if b >= ASCII_A and b <= ASCII_Z
			return true
		else
			return (c == '_')
	

	return false


var char_isdigit = \c ->
	if type(c) == 'string'
		var b = string.byte(c)
		return b >= ASCII_0 and b <= ASCII_9

	return false


var char_isspace = \c ->
	var b = string.byte(c)
	return b >= 9 and b <= 13 or b == 32


var build_64int = \str ->
	var u = str[#str - 2]
	var x = (u == 117 and uint64(0) or int64(0))
	var i = 1
	while str[i] >= ASCII_0 and str[i] <= ASCII_9
		x = 10 * x + (str[i] - ASCII_0)
		i = i + 1

	return x


-- Only lower case letters are accepted.
var byte_to_hexdigit = \b ->
	if b >= ASCII_0 and b <= ASCII_9
		return b - ASCII_0
	else if b >= ASCII_a and b <= ASCII_f
		return 10 + (b - ASCII_a)
	else
		return -1


var build_64hex = \str ->
	var u = str[#str - 2]
	var x = (u == 117 and uint64(0) or int64(0))
	var i = 3
	while str[i]
		var n = byte_to_hexdigit(str[i])
		if n < 0 break 
		x = 16 * x + n
		i = i + 1
	return x


var strnumdump = \str ->
	var t = {}
	for i = 1, #str
		var c = string.sub(str, i, i)
		if char_isalnum(c)
			t[i] = string.byte(c)
		else
			return nil
	return t


var hex_char = \c ->
	if string.match(c, '^%x')
		var b = bit.band(string.byte(c), 15)
		if not char_isdigit(c) b = b + 9 
		return b



return \read, chunkname ->

	-- input stream pointer
	var data, n, p = nil, 0, 0
	-- char and buffer under process
	var ch, buff, comment_buff = '', '', ''
	var newline = nil -- remember the previously found newline
	var indent = nil  -- current indent level
	var minus = nil   -- are we at comment or minus
	var tabs = nil    -- previously used tab char of the file
	
	var lookahead = {
		token = 'TK_eof'
		, value = nil
	}
	-- state to be returned to caller
	var state = {
		chunkname = chunkname
		, lastline = 1
		, line = 1
		, pos = 0
		, token = 'TK_eof'
		, value = nil
	}
	
	var popchar = ->
		var k = p
		var c = string.sub(data, k, k)
		p = k + 1
		n = n - 1
		return c

	var fill = ->
		var stream = read()
		if not stream
			return END_OF_STREAM
		data, n, p = stream, #stream, 1
		return popchar()


	var nextchar = ->
		var c = n > 0 and popchar() or fill()
		state.pos = state.pos + 1
		ch = c
		return c


	var char = \n ->
		var k = p + n
		return string.sub(data, k, k)

	var skip = \len ->
		n = n - len
		p = p + len

	var add_buffer = \c ->
		buff = buff .. c

	var get_buffer = \begin, last ->
		return string.sub(buff, begin + 1, - (last + 1))

	var add_comment = \str ->
		comment_buff = comment_buff .. str

	var get_comment = ->
		var s = comment_buff
		comment_buff = ''
		return s


	var inc_line = ->
		var old = ch
		-- skip `\n' or `\r'
		nextchar()
		if IsNewLine[ch] and ch ~= old
			-- skip `\n\r' or `\r\n'
			nextchar()
		state.line = state.line + 1
		state.pos = 1


	var skip_sep = ->
		var count = 0
		var s = ch
		assert(s == '[' or s == ']')
		add_buffer(s)
		nextchar()
		while ch == '='
			add_buffer(ch)
			nextchar()
			count = count + 1

		return ch == s and count or (-count - 1)


	var lex_number = ->
		var lower = string.lower
		var xp = 'e'
		var c = ch
		if c == '0'
			add_buffer(ch)
			nextchar()
			var xc = ch
			if xc == 'x' or xc == 'X' xp = 'p' 

		while char_isalnum(ch) or ch == '.' or ((ch == '-' or ch == '+') and lower(c) == xp)
			c = lower(ch)
			add_buffer(c)
			nextchar()

		var str = buff
		var x
		if string.sub(str, -1, -1) == 'i'
			var img = tonumber(string.sub(str, 1, -2))
			if img x = complex(0, img) 
		else if string.sub(str, -2, -1) == 'll'
			var t = strnumdump(str)
			if t
				x = xp == 'e' and build_64int(t) or build_64hex(t)
		else
			x = tonumber(str)

		if x
			return str
		else
			lex_error('TK_number', "malformed number")


	var read_long_string = \sep, comment ->
		-- skip 2nd `['
		add_buffer(ch)
		nextchar()
		--if IsNewLine[ch] -- string starts with a newline?
		--    inc_line() -- skip it
		--
		while true
			var c = ch
			if c == END_OF_STREAM
				lex_error('TK_eof', comment and "unfinished long comment" or "unfinished long string")
			else if c == ']'
				if skip_sep() == sep
					-- skip 2nd `]'
					add_buffer(ch)
					nextchar()
					break
			
			else
				add_buffer(c)
				if IsNewLine[c]
					inc_line()
				else
					nextchar()

		--return get_buffer(2 + sep, 2 + sep)
		return get_buffer(0, 0)



	-- this function works tightly with luacode-generator ExpressionRule:Literal
	var read_escape_char = ->
		var c = nextchar() -- Skip the '\\'.
		var esc = IsEscape[c]
		if esc
			-- eg: convert '\n' to '\\n', which is no longer newline
			add_buffer('\\')
			add_buffer(c)
			nextchar()
		else if c == 'x' -- Hexadecimal escape '\xXX'.
			add_buffer('\\')
			add_buffer(c)
			var ch1 = hex_char(nextchar())
			var hc
			if ch1
				add_buffer(ch)
				var ch2 = hex_char(nextchar())
				if ch2
					add_buffer(ch)
					hc = string.char(ch1 * 16 + ch2)

			if not hc
				lex_error('TK_string', "invalid escape sequence")
		
			--add_buffer(hc)
			nextchar()
		else if c == 'z' -- Skip whitespace.
			nextchar()
			while char_isspace(ch)
				if IsNewLine[ch] 
					inc_line() 
				else 
					nextchar()

		else if IsNewLine[c]
			add_buffer('\n')
			inc_line()
		else if c == '\\'
			add_buffer('\\')
			add_buffer(c)
			nextchar()
		else if c == '"' or c == "'"
			add_buffer(c)
			nextchar()
		else if c == END_OF_STREAM
		else
			if not char_isdigit(c)
				lex_error('TK_string', "invalid escape sequence")
		
			add_buffer('\\')
			add_buffer(c)
			var bc = bit.band(string.byte(c), 15) -- Decimal escape '\ddd'.
			if char_isdigit(nextchar())
				add_buffer(ch)
				bc = bc * 10 + bit.band(string.byte(ch), 15)
				if char_isdigit(nextchar())
					add_buffer(ch)
					bc = bc * 10 + bit.band(string.byte(ch), 15)
					nextchar()

			-- cannot save in the end, "\04922" should be "122" but becomes "\4922" which is invalid
			--add_buffer(strchar(bc))
			if bc > 255
				lex_error('TK_string', "invalid escape sequence")



	var read_string = \delim ->
		add_buffer(ch)
		nextchar()
		while ch ~= delim
			var c = ch
			if c == END_OF_STREAM
				lex_error('TK_eof', "unfinished string")
			else if IsNewLine[c]
				lex_error('TK_string', "unfinished string")
			else if c == '\\'
				read_escape_char()
			else
				add_buffer(ch)
				nextchar()

		add_buffer(ch) -- skip delimiter
		nextchar()
		return get_buffer(1, 1)


	var skip_line = ->
		while not IsNewLine[ch] and ch ~= END_OF_STREAM
			add_comment(ch)
			nextchar()


	var tokenize = ->
		
		buff = ''
		if newline
			var ind = newline
			newline = nil
			if ind ~= stack.top()
				if ind > stack.top()
					stack.push(ind)
					return 'TK_indent'
			
				stack.pop()
				if stack.top() ~= ind
					indent = ind
			
				return 'TK_dedent'
		
		else if indent
			if indent > 0 and stack.top() == 0
				lex_error(nil, "unaligned or dangling <indent>")
		
			stack.pop()
			if indent == stack.top()
				indent = nil
		
			return 'TK_dedent'
		else if minus
			minus = nil
			return '-'


		var tab = nil   -- tab char of the current line
		var mixed = false  -- mixing tab and space?
		while true
			var current = ch
			
			if IsNewLine[current]
				tab = nil  -- if come back here, is an empty line, reset tab space tracker
				inc_line()
				var ind = 0
				while ch == ' ' or ch == '\t'
					if not tab
						tab = ch
					else if tab ~= ch
						mixed = true    -- mix tab and space on same line
				
					ind = ind + 1
					nextchar()
			
				if ch ~= END_OF_STREAM
					newline = ind    -- prepare to handle newline
				else
					newline = nil    -- reached EOF, ignore previous newline(s)
			
			else if current == END_OF_STREAM
				if stack.top() > 0
					stack.pop()
					return 'TK_dedent'
			
				return 'TK_eof'
			else if current == ' ' or current == '\t' or current == '\b' or current == '\f'
				-- skip space in between characters
				nextchar()
			else if current == '-'
				nextchar()
				if ch == '-'
					-- is a comment
					newline = nil  -- do not treat newline
					tab = nil  -- or check tab space
					mixed = false
					nextchar()
					add_comment('--')
					if ch == '['
						var sep = skip_sep()
						add_comment(buff)  -- `skip_sep' may have changed buff
						buff = ''
						if sep >= 0
							read_long_string(sep, true) -- long comment
							add_comment(buff)  -- `read_long_string' may have change buff
							buff = '' 
						else
							skip_line()
					
					else
						skip_line()
				
					return 'TK_comment', get_comment()
				else if ch == '>'
					nextchar()
					return 'TK_lambda'
				else if newline
					minus = true
				else
					return '-'
			
			else if newline
				if not mixed and tab
					if not tabs 
						tabs = tab
					else if tab ~= tabs
						mixed = true  -- using tabs and space in different lines

				if mixed
					lex_error(nil, "cannot mix tab and space as indentation")
				return 'TK_newline'
			else
				if char_isalnum(current)
					if char_isdigit(current) -- Numeric literal.
						return 'TK_number', lex_number()
				
					do
						add_buffer(ch)
						nextchar()
					until not char_isalnum(ch)
					var s = get_buffer(0, 0)
					var reserved = Keyword[s]
					if reserved
						return 'TK_' .. s
				
					return 'TK_name', s
				else if current == '@'
					nextchar()
					return 'TK_name', 'self'
				else if current == '['
					var sep = skip_sep()
					if sep >= 0
						var str = read_long_string(sep)
						return 'TK_longstring', str
					else if sep == -1
						return '['
					else
						lex_error('TK_longstring', "delimiter error")
				
				else if current == '='
					nextchar()
					if ch ~= '=' return '='
					else
						nextchar()
						return 'TK_eq' 
				else if current == '<'
					nextchar()
					if ch ~= '=' return '<'
					else
						nextchar()
						return 'TK_le' 
				else if current == '>'
					nextchar()
					if ch ~= '=' return '>'
					else
						nextchar()
						return 'TK_ge' 
				else if current == '~'
					nextchar()
					if ch == '=' 
						nextchar()
						return 'TK_ne'
					else if ch == '>' 
						nextchar()
						return 'TK_curry'
					return '~'
				else if current == ':'
					nextchar()
					if ch ~= ':' return ':'
					else
						nextchar()
						return 'TK_label' 
				else if current == '"' or current == "'"
					var str = read_string(current)
					return 'TK_string', str
				else if current == '.'
					add_buffer(ch)
					nextchar()
					if ch == '.'
						nextchar()
						if ch == '.'
							nextchar()
							return 'TK_dots' -- ...
					
						return 'TK_concat' -- ..
					else if not char_isdigit(ch)
						return '.'
					else
						return 'TK_number', lex_number()
				
				else
					nextchar()
					return current -- Single-char tokens (+ - / ...).


	var lex = ->
		var token, value
		while true
			token, value = tokenize()
			if token ~= 'TK_comment' 
				break
		return token, value


	
	var lex_error = \token, em, ... ->
		var msg = fmt_error(token, em, "%s near %s")
		throw(chunkname, state.line, em, ...)


	var parse_error = \token, em, ... ->
		var msg = fmt_error(token, em, "%s instead of %s")
		throw(chunkname, state.line, em, ...)


	var step = ->
		state.lastline = state.line
		if lookahead.token == 'TK_eof' -- No lookahead token
			state.token, state.value = lex()
		else
			state.token, state.value = lookahead.token, lookahead.value
			lookahead.token = 'TK_eof'
		return state.token, state.value

	var next = ->
		if lookahead.token == 'TK_eof'
			lookahead.token, lookahead.value = lex()
		return lookahead.token, lookahead.value


	var lexer = setmetatable(state, { __index = {
		tostr = token2str
		, error = parse_error
		, step = step
		, next = next
	}})


	nextchar()
	if ch == '\xef' and n >= 2 and char(0) == '\xbb' and char(1) == '\xbf' -- Skip UTF-8 BOM (if buffered).
		n = n - 2
		p = p + 2
		nextchar()

	stack.push(0)
	if ch == '#'
		do
			nextchar()
			if ch == END_OF_STREAM return lexer
		until IsNewLine[ch]
		inc_line()

	return lexer