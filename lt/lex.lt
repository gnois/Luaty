var bit = require('bit')
var ffi = require('ffi')
var chars = require('lua.chars')
var stack = require('lua.stack')
var reserved = require('lua.reserved')
var Keyword = reserved.Keyword

var complex = ffi.typeof('complex')
var is = chars.is
var build = chars.build

var END_OF_STREAM = -1

var TokenSymbol = { TK_name = 'identifier', TK_indent = '<indent>', TK_dedent = '<dedent>', TK_newline = '<newline>', TK_eof = '<eof>' }
var IsNewLine = { ['\n'] = true, ['\r'] = true }
var IsEscape = { a = true, b = true, f = true, n = true, r = true, t = true, v = true }


var token2str = \tok ->
	if string.match(tok, "^TK_")
		return string.sub(tok, 4)
	return tok


var token2text = \tok ->
	var t = TokenSymbol[tok]
	if not t
		return "`" .. token2str(tok) .. "`"
	return t

return \read, warn ->

	-- input stream pointer
	var data, n, p = nil, 0, 0
	-- char and buffer under process
	var ch, comment_buff = '', ''
	var buff, bi = {}, 1
	var newline = nil -- remember the previously found newline
	var indent = nil  -- current indent level
	var minus = nil   -- are we at comment or minus
	var tabs = nil    -- previously used tab char of the file
	
	var lookahead = {
		token = 'TK_eof'
		, value = nil
	}
	-- state to be returned to caller
	var state = {
		prevline = 1
		, prevcol = 1
		, line = 1
		, col = 1
		, token = 'TK_eof'
		, value = nil
	}

	var fmt_token = \token ->
		if token
			if token == 'TK_name' or token == 'TK_string' or token == 'TK_number'
				var tok = table.concat(buff)
				-- replace % with %%, so as not to confuse string.format() later
				return (string.gsub(tok, "%%.", \pc -> return "%" .. pc))
			return token2text(token)


	var lex_error = \token, em, ... ->
		var tok = fmt_token(token)
		if tok
			em = em .. " near " .. tok
		-- if the buff is too long, col will be negative, so don't minus away the length of buff
		var col = #buff
		if col > state.col
			col = state.col
		else
			col = state.col - col
		warn(state.line, col, 11, string.format(em, ...))


	var popchar = ->
		var k = p
		var c = string.sub(data, k, k)
		p = k + 1
		n = n - 1
		return c

	var fill = ->
		var stream = read()
		if not stream
			return END_OF_STREAM
		data, n, p = stream, #stream, 1
		return popchar()

	var nextchar = ->
		var c = n > 0 and popchar() or fill()
		state.col = state.col + 1
		ch = c
		return c

	var char = \m ->
		var k = p + m
		return string.sub(data, k, k)

	--`
	var skip = \len ->
		n = n - len
		p = p + len
	--`
	
	var add_buffer = \c ->
		buff[bi] = c
		bi = bi + 1

	var clear_buffer = ->
		buff, bi = {}, 1
		
	var get_buffer = \begin, last ->
		return table.concat(buff, '', begin + 1, #buff - last) -- -(last + 1))

	var add_comment = \str ->
		comment_buff = comment_buff .. str

	var get_comment = ->
		var s = comment_buff
		comment_buff = ''
		return s


	var inc_line = ->
		var old = ch
		-- skip `\n' or `\r'
		nextchar()
		if IsNewLine[ch] and ch ~= old
			-- skip `\n\r' or `\r\n'
			nextchar()
		state.line = state.line + 1
		state.col = 1


	var add_eq = ->
		var count = 0
		var s = ch
		assert(s == '[' or s == ']')
		add_buffer(s)
		nextchar()
		while ch == '='
			add_buffer(ch)
			nextchar()
			count = count + 1

		return ch == s and count or (-count - 1)

	var add_bquote = ->
		var count = 1
		var s = ch
		assert(s == '`')
		add_buffer(s)
		nextchar()
		while ch == '`'
			add_buffer(ch)
			nextchar()
			count = count + 1
		return count


	var lex_number = ->
		var lower = string.lower
		var xp = 'e'
		var c = ch
		if c == '0'
			add_buffer(ch)
			nextchar()
			var xc = ch
			if xc == 'x' or xc == 'X' xp = 'p' 

		while is.alnum(ch) or ch == '.' or ((ch == '-' or ch == '+') and lower(c) == xp)
			c = lower(ch)
			add_buffer(c)
			nextchar()

		var str = table.concat(buff)
		var x
		if string.sub(str, -1, -1) == 'i'
			var img = tonumber(string.sub(str, 1, -2))
			if img x = complex(0, img) 
		else if string.sub(str, -2, -1) == 'll'
			var t = chars.strnumdump(str)
			if t
				x = xp == 'e' and build.int64(t) or build.hex64(t)
		else
			x = tonumber(str)

		if x
			return str
		else
			lex_error('TK_number', "malformed number")


	var read_long_string = \sep, comment ->
		var begin = state.line
		-- skip 2nd [
		add_buffer(ch)
		nextchar()
		--if IsNewLine[ch] -- string starts with a newline?
		--    inc_line() -- skip it
		--
		while true
			if ch == END_OF_STREAM
				lex_error('TK_eof', (comment and "unfinished long comment" or "unfinished long string") .. " from line %d till", begin)
				break
			else if ch == ']'
				if add_eq() == sep
					-- skip 2nd ]
					add_buffer(ch)
					nextchar()
					break
			else
				add_buffer(ch)
				if IsNewLine[ch]
					inc_line()
				else
					nextchar()
		
		var delim = string.rep('=', sep)
		var quote = string.rep('`', sep + 1)
		lex_error(nil, "use " .. quote .. " as long string delimiter instead of [" .. delim .. "[ ... ]" .. delim .. "]")
		--return get_buffer(2 + sep, 2 + sep)
		return get_buffer(0, 0)


	var read_long_bquote_string = \sep, comment ->
		var begin = state.line
		--if IsNewLine[ch] -- string starts with a newline?
		--    inc_line() -- skip it
		while true
			if ch == END_OF_STREAM
				lex_error('TK_eof', (comment and "unfinished long comment" or "unfinished long string") .. " from line %d till", begin)
				break
			else if ch == '`'
				if add_bquote() == sep
					break
			else
				if ch == ']'
					if add_eq() + 1 == sep
						var delim = string.rep('=', sep - 1)
						lex_error(nil, "long string delimiter conflict due to " .. ch .. delim .. ch .. "; please use more than " .. sep .. " backquote")

				add_buffer(ch)
				if IsNewLine[ch]
					inc_line()
				else
					nextchar()
		--return get_buffer(2 + sep, 2 + sep)
		return get_buffer(0, 0)


	-- this function works tightly with generator ExpressionRule:Literal
	var read_escape_char = ->
		var c = nextchar() -- Skip the '\\'.
		var esc = IsEscape[c]
		if esc
			-- eg: convert '\n' to '\\n', which is no longer newline
			add_buffer('\\')
			add_buffer(c)
			nextchar()
		else if c == 'x' -- Hexadecimal escape '\xXX'.
			add_buffer('\\')
			add_buffer(c)
			var ch1 = chars.hex(nextchar())
			var hc
			if ch1
				add_buffer(ch)
				var ch2 = chars.hex(nextchar())
				if ch2
					add_buffer(ch)
					hc = string.char(ch1 * 16 + ch2)
			if not hc
				lex_error('TK_string', "invalid escape sequence")
			--add_buffer(hc)
			nextchar()
		else if c == 'z' -- Skip whitespace.
			nextchar()
			while is.space(ch)
				if IsNewLine[ch] 
					inc_line() 
				else 
					nextchar()

		else if IsNewLine[c]
			add_buffer('\n')
			inc_line()
		else if c == '\\'
			add_buffer('\\')
			add_buffer(c)
			nextchar()
		else if c == '"' or c == "'"
			add_buffer(c)
			nextchar()
		else if c == END_OF_STREAM
		else
			if not is.digit(c)
				lex_error('TK_string', "invalid escape character \\" .. c)
		
			add_buffer('\\')
			add_buffer(c)
			var bc = bit.band(string.byte(c), 15) -- Decimal escape '\ddd'.
			if is.digit(nextchar())
				add_buffer(ch)
				bc = bc * 10 + bit.band(string.byte(ch), 15)
				if is.digit(nextchar())
					add_buffer(ch)
					bc = bc * 10 + bit.band(string.byte(ch), 15)
					nextchar()
			-- cannot save in the end, "\04922" should be "122" but becomes "\4922" which is invalid
			--add_buffer(strchar(bc))
			if bc > 255
				lex_error('TK_string', "invalid escape sequence")



	var read_string = \delim ->
		add_buffer(ch)
		nextchar()
		while ch ~= delim
			if ch == END_OF_STREAM
				lex_error('TK_eof', "unfinished string")
				break
			else if IsNewLine[ch]
				lex_error('TK_string', "unfinished string")
				break
			else if ch == '\\'
				read_escape_char()
			else
				add_buffer(ch)
				nextchar()

		add_buffer(ch) -- skip delimiter
		nextchar()
		return get_buffer(1, 1)




	var tokenize = ->
		
		clear_buffer()
		if newline
			var ind = newline
			newline = nil
			if ind ~= stack.top()
				if ind > stack.top()
					stack.push(ind)
					return 'TK_indent'
			
				stack.pop()
				if stack.top() ~= ind
					indent = ind
				return 'TK_dedent'
		
		else if indent
			if indent > 0 and stack.top() == 0
				lex_error(nil, "unaligned or dangling <indent>")
			stack.pop()
			if indent == stack.top()
				indent = nil
		
			return 'TK_dedent'

		var tab = nil   -- tab char of the current line
		var mixed = false  -- mixing tab and space?
		while true
			if minus
				minus = nil
				return '-'

			var c = ch
			if IsNewLine[ch]
				tab = nil  -- if come back here, is an empty line, reset tab space tracker
				inc_line()
				var ind = 0
				while ch == ' ' or ch == '\t'
					if not tab
						tab = ch
					else if tab ~= ch
						mixed = true    -- mix tab and space on same line
				
					ind = ind + 1
					nextchar()
			
				if ch ~= END_OF_STREAM
					newline = ind    -- prepare to handle newline
				else
					newline = nil    -- reached EOF, ignore previous newline(s)
			
			else if ch == END_OF_STREAM
				if stack.top() > 0
					stack.pop()
					return 'TK_dedent'
			
				return 'TK_eof'
			else if ch == ' ' or ch == '\t' or ch == '\b' or ch == '\f'
				-- skip space in between characters
				nextchar()
			-- comment must be earlier than newline check, bcoz we ignore newline, indents, space/tab for comment line
			else if ch == '-'
				nextchar()
				if ch == '-'
					-- is a comment
					newline = nil  -- do not treat newline
					tab = nil  -- or check tab space
					mixed = false
					nextchar()
					add_comment('--')
					if ch == '['
						var sep = add_eq()
						add_comment(table.concat(buff))  -- add_eq() may have changed buff
						clear_buffer()
						if sep >= 0
							read_long_string(sep, true)
							add_comment(table.concat(buff))  -- buff has been changed
							clear_buffer()
						else
							while not IsNewLine[ch] and ch ~= END_OF_STREAM
								add_comment(ch)
								nextchar()
					else if ch == '`'
						var sep = add_bquote()
						add_comment(table.concat(buff))  -- add_bquote() may have changed buff
						clear_buffer()
						read_long_bquote_string(sep, true)
						add_comment(table.concat(buff))  -- buff has been changed
						clear_buffer()
					else
						while not IsNewLine[ch] and ch ~= END_OF_STREAM
							add_comment(ch)
							nextchar()
					return 'TK_comment', get_comment()
				else if ch == '>'
					nextchar()
					return '->'
				else if newline
					-- owe a minus
					minus = true
					return 'TK_newline'
				else
					return '-'

			else if newline
				if not mixed and tab
					if not tabs 
						tabs = tab
					else if tab ~= tabs
						mixed = true  -- using tabs and space in different lines

				if mixed
					lex_error(nil, "cannot mix tab and space as indentation")
				return 'TK_newline'
			else
				if is.alnum(ch)
					if is.digit(ch) -- Numeric literal.
						return 'TK_number', lex_number()

					do
						add_buffer(ch)
						nextchar()
					until not is.alnum(ch)
					var s = get_buffer(0, 0)
					if Keyword[s]
						return 'TK_' .. s
				
					return 'TK_name', s
				else if ch == '@'
					nextchar()
					return 'TK_name', '@'
				else if ch == '['
					var sep = add_eq()
					-- if [=..., we treat it as long string
					if sep > 0
						var str = read_long_string(sep)
						return 'TK_longstring', str
					-- [[ is no longer long string. we return [, [ one by one
					else if sep == 0 or sep == -1
						return '['
					else
						lex_error(nil, "invalid long string delimiter")
				
				else if ch == '`'
					var sep = add_bquote()
					var str = read_long_bquote_string(sep)
					return 'TK_longstring', str

				else if ch == '='
					nextchar()
					if ch == '='
						nextchar()
						return '=='
					else if ch == '>'
						nextchar()
						return '=>'
					return '='
				else if ch == '<'
					nextchar()
					if ch ~= '=' return '<'
					else
						nextchar()
						return '<='
				else if ch == '>'
					nextchar()
					if ch ~= '=' return '>'
					else
						nextchar()
						return '>=' 
				else if ch == '~'
					nextchar()
					if ch == '='
						nextchar()
						return '~='
					else if ch == '>'
						nextchar()
						return '~>'
					return '~'
				else if ch == ':'
					nextchar()
					if ch ~= ':' return ':'
					else
						nextchar()
						return '::' 
				else if ch == '"' or ch == "'"
					var str = read_string(ch)
					return 'TK_string', str
				else if ch == '.'
					add_buffer(ch)
					nextchar()
					if ch == '.'
						nextchar()
						if ch == '.'
							nextchar()
							return '...'
					
						return '..'
					else if not is.digit(ch)
						return '.'
					else
						return 'TK_number', lex_number()
				else
					-- Single-char tokens (+ - / ...).
					nextchar()
					return c


	var lex = ->
		var token, value
		while true
			token, value = tokenize()
			if token ~= 'TK_comment' 
				break
		return token, value

	var step = ->
		state.prevline = state.line
		state.prevcol = state.col
		if lookahead.token == 'TK_eof' -- No lookahead token
			state.token, state.value = lex()
		else
			state.token, state.value = lookahead.token, lookahead.value
			lookahead.token = 'TK_eof'
		return state.token, state.value

	var preview = ->
		if lookahead.token == 'TK_eof'
			lookahead.token, lookahead.value = lex()
		return lookahead.token, lookahead.value

	var loc = ->
		return {
			line = state.line
			, col = state.prevcol or state.col
		}

	var lexer = setmetatable(state, { __index = {
		tostr = token2str
		, astext = token2text
		, step = step
		, next = preview
		, loc = loc
	}})


	nextchar()
	if ch == '\xef' and n >= 2 and char(0) == '\xbb' and char(1) == '\xbf' -- Skip UTF-8 BOM (if buffered).
		n = n - 2
		p = p + 2
		nextchar()

	stack.push(0)
	if ch == '#'
		do
			nextchar()
			if ch == END_OF_STREAM return lexer
		until IsNewLine[ch]
		inc_line()

	return lexer