var chars = require("lt.chars")
var stack = require("lt.stack")
var Keyword = require("lt.reserved")

var is = chars.is
var build = chars.build

var END_OF_STREAM = -1

var TokenSymbol = { TK_lambda = '->', TK_curry = '~>', TK_ge = '>=', TK_le = '<=' , TK_concat = '..', TK_eq = '==', TK_ne = '~=', TK_indent = '<indent>', TK_dedent = '<dedent>', TK_newline = '<newline>', TK_eof = '<eof>' }

var IsNewLine = { ['\n'] = true, ['\r'] = true }
var IsEscape = { a = true, b = true, f = true, n = true, r = true, t = true, v = true }


var token2str = \tok ->
	if string.match(tok, "^TK_")
		return TokenSymbol[tok] or string.sub(tok, 4)
	return tok


return \read, chunkname ->

	-- input stream pointer
	var data, n, p = nil, 0, 0
	-- char and buffer under process
	var ch, comment_buff = '', ''
	var buff, bi = {}, 0
	var newline = nil -- remember the previously found newline
	var indent = nil  -- current indent level
	var minus = nil   -- are we at comment or minus
	var tabs = nil    -- previously used tab char of the file
	
	var lookahead = {
		token = 'TK_eof'
		, value = nil
	}
	-- state to be returned to caller
	var state = {
		chunkname = chunkname
		, prevline = 1
		, prevpos = 1
		, line = 1
		, pos = 1
		, token = 'TK_eof'
		, value = nil
	}
	-- keeps all errors as {l(ine) = l, c(ol) = c, msg = msg}
	var warnings = {}

	var warn = \w ->
		for i, m in ipairs(warnings)
			if w.l == m.l and w.c == m.c -- and w.msg == m.msg
				return  -- skip same error
			if w.l < m.l or (w.l == m.l and w.c < m.c)
				-- insert
				table.insert(warnings, i, w)
				return
		-- append
		table.insert(warnings, w)


	var fmt_token = \token ->
		if token
			var tok
			if token == 'TK_name' or token == 'TK_string' or token == 'TK_number'
				tok = table.concat(buff)
			else
				tok = string.format("'%s'", token2str(token))
			-- replace % with %%, so as not to confuse string.format() later
			return (string.gsub(tok, "%%.", \p -> return '%' .. p ))


	var lex_error = \token, em, ... ->
		var tok = fmt_token(token)
		if tok
			em = em .. " near " .. tok
		-- if the buff is too long, pos will be negative, so don't minus away the length of buff
		var pos = #buff
		if pos > state.pos
			pos = state.pos
		else
			pos = state.pos - pos
		warn({
			msg = string.format(em, ...)
			, l = state.line
			, c = pos
		})
		--var msg = string.format("%s: (%d,%d)  " .. em, state.chunkname, state.line, pos, ...)
		--error("LT-ERROR" .. msg, 0)


	var parse_error = \state, em, ... ->
		warn({
			msg = string.format(em, ...)
			, l = state.line
			, c = state.prevpos
		})


	var popchar = ->
		var k = p
		var c = string.sub(data, k, k)
		p = k + 1
		n = n - 1
		return c

	var fill = ->
		var stream = read()
		if not stream
			return END_OF_STREAM
		data, n, p = stream, #stream, 1
		return popchar()

	var nextchar = ->
		var c = n > 0 and popchar() or fill()
		state.pos = state.pos + 1
		ch = c
		return c

	var char = \n ->
		var k = p + n
		return string.sub(data, k, k)

	var skip = \len ->
		n = n - len
		p = p + len


	var add_buffer = \c ->
		bi = bi + 1
		buff[bi] = c

	var clear_buffer = ->
		buff, bi = {}, 0
		
	var get_buffer = \begin, last ->
		return table.concat(buff, '', begin + 1, #buff - last) -- -(last + 1))

	var add_comment = \str ->
		comment_buff = comment_buff .. str

	var get_comment = ->
		var s = comment_buff
		comment_buff = ''
		return s


	var inc_line = ->
		var old = ch
		-- skip `\n' or `\r'
		nextchar()
		if IsNewLine[ch] and ch ~= old
			-- skip `\n\r' or `\r\n'
			nextchar()
		state.line = state.line + 1
		state.pos = 1


	var skip_sep = ->
		var count = 0
		var s = ch
		assert(s == '[' or s == ']')
		add_buffer(s)
		nextchar()
		while ch == '='
			add_buffer(ch)
			nextchar()
			count = count + 1

		return ch == s and count or (-count - 1)


	var lex_number = ->
		var lower = string.lower
		var xp = 'e'
		var c = ch
		if c == '0'
			add_buffer(ch)
			nextchar()
			var xc = ch
			if xc == 'x' or xc == 'X' xp = 'p' 

		while is.alnum(ch) or ch == '.' or ((ch == '-' or ch == '+') and lower(c) == xp)
			c = lower(ch)
			add_buffer(c)
			nextchar()

		var str = table.concat(buff)
		var x
		if string.sub(str, -1, -1) == 'i'
			var img = tonumber(string.sub(str, 1, -2))
			if img x = complex(0, img) 
		else if string.sub(str, -2, -1) == 'll'
			var t = chars.strnumdump(str)
			if t
				x = xp == 'e' and build.int64(t) or build.hex64(t)
		else
			x = tonumber(str)

		if x
			return str
		else
			lex_error('TK_number', "malformed number")


	var read_long_string = \sep, comment ->
		var begin = state.line
		-- skip 2nd `['
		add_buffer(ch)
		nextchar()
		--if IsNewLine[ch] -- string starts with a newline?
		--    inc_line() -- skip it
		--
		while true
			var c = ch
			if c == END_OF_STREAM
				lex_error('TK_eof', (comment and "unfinished long comment" or "unfinished long string") .. " from line %d till", begin)
			else if c == ']'
				if skip_sep() == sep
					-- skip 2nd `]'
					add_buffer(ch)
					nextchar()
					break
			else
				add_buffer(c)
				if IsNewLine[c]
					inc_line()
				else
					nextchar()
		--return get_buffer(2 + sep, 2 + sep)
		return get_buffer(0, 0)



	-- this function works tightly with luacode-generator ExpressionRule:Literal
	var read_escape_char = ->
		var c = nextchar() -- Skip the '\\'.
		var esc = IsEscape[c]
		if esc
			-- eg: convert '\n' to '\\n', which is no longer newline
			add_buffer('\\')
			add_buffer(c)
			nextchar()
		else if c == 'x' -- Hexadecimal escape '\xXX'.
			add_buffer('\\')
			add_buffer(c)
			var ch1 = chars.hex(nextchar())
			var hc
			if ch1
				add_buffer(ch)
				var ch2 = chars.hex(nextchar())
				if ch2
					add_buffer(ch)
					hc = string.char(ch1 * 16 + ch2)
			if not hc
				lex_error('TK_string', "invalid escape sequence")
			--add_buffer(hc)
			nextchar()
		else if c == 'z' -- Skip whitespace.
			nextchar()
			while is.space(ch)
				if IsNewLine[ch] 
					inc_line() 
				else 
					nextchar()

		else if IsNewLine[c]
			add_buffer('\n')
			inc_line()
		else if c == '\\'
			add_buffer('\\')
			add_buffer(c)
			nextchar()
		else if c == '"' or c == "'"
			add_buffer(c)
			nextchar()
		else if c == END_OF_STREAM
		else
			if not is.digit(c)
				lex_error('TK_string', "invalid escape character \\" .. c)
		
			add_buffer('\\')
			add_buffer(c)
			var bc = bit.band(string.byte(c), 15) -- Decimal escape '\ddd'.
			if is.digit(nextchar())
				add_buffer(ch)
				bc = bc * 10 + bit.band(string.byte(ch), 15)
				if is.digit(nextchar())
					add_buffer(ch)
					bc = bc * 10 + bit.band(string.byte(ch), 15)
					nextchar()
			-- cannot save in the end, "\04922" should be "122" but becomes "\4922" which is invalid
			--add_buffer(strchar(bc))
			if bc > 255
				lex_error('TK_string', "invalid escape sequence")



	var read_string = \delim ->
		add_buffer(ch)
		nextchar()
		while ch ~= delim
			var c = ch
			if c == END_OF_STREAM
				lex_error('TK_eof', "unfinished string")
			else if IsNewLine[c]
				lex_error('TK_string', "unfinished string")
			else if c == '\\'
				read_escape_char()
			else
				add_buffer(ch)
				nextchar()

		add_buffer(ch) -- skip delimiter
		nextchar()
		return get_buffer(1, 1)


	var skip_line = ->
		while not IsNewLine[ch] and ch ~= END_OF_STREAM
			add_comment(ch)
			nextchar()


	var tokenize = ->
		
		clear_buffer()
		if newline
			var ind = newline
			newline = nil
			if ind ~= stack.top()
				if ind > stack.top()
					stack.push(ind)
					return 'TK_indent'
			
				stack.pop()
				if stack.top() ~= ind
					indent = ind
				return 'TK_dedent'
		
		else if indent
			if indent > 0 and stack.top() == 0
				lex_error(nil, "unaligned or dangling <indent>")
			stack.pop()
			if indent == stack.top()
				indent = nil
		
			return 'TK_dedent'
		else if minus
			minus = nil
			return '-'

		var tab = nil   -- tab char of the current line
		var mixed = false  -- mixing tab and space?
		while true
			var c = ch
			
			if IsNewLine[ch]
				tab = nil  -- if come back here, is an empty line, reset tab space tracker
				inc_line()
				var ind = 0
				while ch == ' ' or ch == '\t'
					if not tab
						tab = ch
					else if tab ~= ch
						mixed = true    -- mix tab and space on same line
				
					ind = ind + 1
					nextchar()
			
				if ch ~= END_OF_STREAM
					newline = ind    -- prepare to handle newline
				else
					newline = nil    -- reached EOF, ignore previous newline(s)
			
			else if ch == END_OF_STREAM
				if stack.top() > 0
					stack.pop()
					return 'TK_dedent'
			
				return 'TK_eof'
			else if ch == ' ' or ch == '\t' or ch == '\b' or ch == '\f'
				-- skip space in between characters
				nextchar()
			else if ch == '-'
				nextchar()
				if ch == '-'
					-- is a comment
					newline = nil  -- do not treat newline
					tab = nil  -- or check tab space
					mixed = false
					nextchar()
					add_comment('--')
					if ch == '['
						var sep = skip_sep()
						add_comment(table.concat(buff))  -- `skip_sep' may have changed buff
						clear_buffer()
						if sep >= 0
							read_long_string(sep, true) -- long comment
							add_comment(table.concat(buff))  -- `read_long_string' may have change buff
							clear_buffer()
						else
							skip_line()
					
					else
						skip_line()
				
					return 'TK_comment', get_comment()
				else if ch == '>'
					nextchar()
					return 'TK_lambda'
				else if newline
					minus = true
				else
					return '-'
			
			else if newline
				if not mixed and tab
					if not tabs 
						tabs = tab
					else if tab ~= tabs
						mixed = true  -- using tabs and space in different lines

				if mixed
					lex_error(nil, "cannot mix tab and space as indentation")
				return 'TK_newline'
			else
				if is.alnum(ch)
					if is.digit(ch) -- Numeric literal.
						return 'TK_number', lex_number()

					do
						add_buffer(ch)
						nextchar()
					until not is.alnum(ch)
					var s = get_buffer(0, 0)
					var reserved = Keyword[s]
					if reserved
						return 'TK_' .. s
				
					return 'TK_name', s
				else if ch == '@'
					nextchar()
					return 'TK_name', 'self'
				else if ch == '['
					var sep = skip_sep()
					if sep >= 0
						var str = read_long_string(sep)
						return 'TK_longstring', str
					else if sep == -1
						return '['
					else
						lex_error('TK_longstring', "long string delimiter error")
				
				else if ch == '='
					nextchar()
					if ch ~= '=' return '='
					else
						nextchar()
						return 'TK_eq' 
				else if ch == '<'
					nextchar()
					if ch ~= '=' return '<'
					else
						nextchar()
						return 'TK_le' 
				else if ch == '>'
					nextchar()
					if ch ~= '=' return '>'
					else
						nextchar()
						return 'TK_ge' 
				else if ch == '~'
					nextchar()
					if ch == '=' 
						nextchar()
						return 'TK_ne'
					else if ch == '>' 
						nextchar()
						return 'TK_curry'
					return '~'
				else if ch == ':'
					nextchar()
					if ch ~= ':' return ':'
					else
						nextchar()
						return 'TK_label' 
				else if ch == '"' or ch == "'"
					var str = read_string(ch)
					return 'TK_string', str
				else if ch == '.'
					add_buffer(ch)
					nextchar()
					if ch == '.'
						nextchar()
						if ch == '.'
							nextchar()
							return 'TK_dots' -- ...
					
						return 'TK_concat' -- ..
					else if not is.digit(ch)
						return '.'
					else
						return 'TK_number', lex_number()
				else
					-- Single-char tokens (+ - / ...).
					nextchar()
					return c


	var lex = ->
		var token, value
		while true
			token, value = tokenize()
			if token ~= 'TK_comment' 
				break
		return token, value

	var step = ->
		state.prevline = state.line
		state.prevpos = state.pos
		if lookahead.token == 'TK_eof' -- No lookahead token
			state.token, state.value = lex()
		else
			state.token, state.value = lookahead.token, lookahead.value
			lookahead.token = 'TK_eof'
		return state.token, state.value

	var next = ->
		if lookahead.token == 'TK_eof'
			lookahead.token, lookahead.value = lex()
		return lookahead.token, lookahead.value


	var lexer = setmetatable(state, { __index = {
		tostr = token2str
		, step = step
		, next = next
		, error = parse_error
		, warnings = warnings
	}})


	nextchar()
	if ch == '\xef' and n >= 2 and char(0) == '\xbb' and char(1) == '\xbf' -- Skip UTF-8 BOM (if buffered).
		n = n - 2
		p = p + 2
		nextchar()

	stack.push(0)
	if ch == '#'
		do
			nextchar()
			if ch == END_OF_STREAM return lexer
		until IsNewLine[ch]
		inc_line()

	return lexer